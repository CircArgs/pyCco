{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0204f5e7-92dc-405d-bfae-b2dc68464d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycco.tokenizers import *\n",
    "from pycco.ast import *\n",
    "from pycco.parsers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b90ee94-47bb-42a8-ade4-a40568bff719",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_code = \"\"\"\n",
    "int main(args) {\n",
    "    int* x = 42;\n",
    "        /*\n",
    "    multiline comment\n",
    "    */\n",
    "    printf(\"Hello, World!\");\n",
    "    return 0;\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8921f400-b83c-4528-a9e7-0991e184a679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParserResult(index=1, result=int, description=\"TYPE\")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokenize('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d13c4cd9-2c39-4c81-abc4-3f71bdf30028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParserResult(index=4, result=[Token(kind=<TokenKind.TYPE: 3>, value='int', start=3, end=5), Token(kind=<TokenKind.OPERATOR: 5>, value='*', start=4, end=4), Token(kind=<TokenKind.IDENTIFIER: 1>, value='x', start=6, end=6), Token(kind=<TokenKind.SYMBOL: 4>, value=';', start=7, end=7)], description=(((\"TYPE\" + \"*\"?) + \"IDENTIFIER\") + \";\"))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variable_decl(tokenize('int* x;'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e44275a4-4f75-41b5-9691-8c627d7ef872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Token(kind=<TokenKind.TYPE: 3>, value='int', start=4, end=6),\n",
       " Token(kind=<TokenKind.IDENTIFIER: 1>, value='main', start=9, end=12),\n",
       " Token(kind=<TokenKind.SYMBOL: 4>, value='(', start=10, end=10),\n",
       " Token(kind=<TokenKind.IDENTIFIER: 1>, value='args', start=14, end=17),\n",
       " Token(kind=<TokenKind.SYMBOL: 4>, value=')', start=15, end=15),\n",
       " Token(kind=<TokenKind.SYMBOL: 4>, value='{', start=17, end=17),\n",
       " Token(kind=<TokenKind.TYPE: 3>, value='int', start=25, end=27),\n",
       " Token(kind=<TokenKind.OPERATOR: 5>, value='*', start=26, end=26),\n",
       " Token(kind=<TokenKind.IDENTIFIER: 1>, value='x', start=28, end=28),\n",
       " Token(kind=<TokenKind.OPERATOR: 5>, value='=', start=30, end=30),\n",
       " Token(kind=<TokenKind.NUMBER: 7>, value='42', start=33, end=34),\n",
       " Token(kind=<TokenKind.SYMBOL: 4>, value=';', start=34, end=34),\n",
       " Token(kind=<TokenKind.IDENTIFIER: 1>, value='printf', start=85, end=90),\n",
       " Token(kind=<TokenKind.SYMBOL: 4>, value='(', start=86, end=86),\n",
       " Token(kind=<TokenKind.STRING_LITERAL: 6>, value='Hello, World!', start=101, end=113),\n",
       " Token(kind=<TokenKind.SYMBOL: 4>, value=')', start=102, end=102),\n",
       " Token(kind=<TokenKind.SYMBOL: 4>, value=';', start=103, end=103),\n",
       " Token(kind=<TokenKind.KEYWORD: 2>, value='return', start=114, end=119),\n",
       " Token(kind=<TokenKind.NUMBER: 7>, value='0', start=116, end=116),\n",
       " Token(kind=<TokenKind.SYMBOL: 4>, value=';', start=117, end=117),\n",
       " Token(kind=<TokenKind.SYMBOL: 4>, value='}', start=119, end=119)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(source_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d063a87-ae19-43b2-8554-c95a06cac812",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_code = \"\"\"\n",
    "int main() {\n",
    "    int x = 42;\n",
    "    /*\n",
    "    multiline comment\n",
    "    */\n",
    "    printf(Hello, World!\");\n",
    "    return 0;\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9289690d-cc80-4cba-b456-1423b8091781",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Tokenization Error:\nUnexpected token at line 7, column 25:\n\n    multiline comment\n    */\n    printf(Hello, World!\");\n                        ^\n    return 0;\n}\nExpected one of whitespace, comment, keywords, keywords, (one of {, }, (, ), ;, ,, [, ], ., -> @ create_token), (one of +, -, *, /, %, =, ==, !=, <, >, <=, >=, &&, ||, !, &, |, ^, <<, >> @ create_token), number, string literal, identifier.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbad_code\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/pyCco/pycco/tokenizers.py:167\u001b[0m, in \u001b[0;36mtokenize\u001b[0;34m(source)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtokenize\u001b[39m(source: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Token]:\n\u001b[0;32m--> 167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miter_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/pyCco/pycco/tokenizers.py:150\u001b[0m, in \u001b[0;36miter_tokenize\u001b[0;34m(source)\u001b[0m\n\u001b[1;32m    147\u001b[0m     pointer \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m column_number \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m^\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;66;03m# Raise detailed error\u001b[39;00m\n\u001b[0;32m--> 150\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    151\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTokenization Error:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    152\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected token at line \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mline_number\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, column \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolumn_number\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    153\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbefore_error\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_line\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpointer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mafter_error\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdescription\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    158\u001b[0m     )\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m token\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (TokenKind\u001b[38;5;241m.\u001b[39mWHITESPACE, TokenKind\u001b[38;5;241m.\u001b[39mCOMMENT):\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m token\n",
      "\u001b[0;31mValueError\u001b[0m: Tokenization Error:\nUnexpected token at line 7, column 25:\n\n    multiline comment\n    */\n    printf(Hello, World!\");\n                        ^\n    return 0;\n}\nExpected one of whitespace, comment, keywords, keywords, (one of {, }, (, ), ;, ,, [, ], ., -> @ create_token), (one of +, -, *, /, %, =, ==, !=, <, >, <=, >=, &&, ||, !, &, |, ^, <<, >> @ create_token), number, string literal, identifier.\n"
     ]
    }
   ],
   "source": [
    "tokenize(bad_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20db9086-5644-45b2-aa20-b5dbac88216d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parser(one of whitespace, comment, keywords, keywords, (one of {, }, (, ), ;, ,, [, ], ., -> @ create_token), (one of +, -, *, /, %, =, ==, !=, <, >, <=, >=, &&, ||, !, &, |, ^, <<, >> @ create_token), number, string literal, identifier)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7330a2e2-8f1c-4491-8239-2fd7a2445851",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
